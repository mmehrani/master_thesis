\documentclass[12pt,onecolumn,a4paper]{article}
\usepackage{epsfig,amsthm,amsmath,booktabs,csquotes}
\usepackage [pagebackref=true, colorlinks, linkcolor=blue, citecolor=magenta, urlcolor=cyan] {hyperref}
\usepackage{color,xcolor}

\usepackage{titlesec} %include more subsection than subsubsection

\usepackage{subcaption}
\usepackage[labelformat=parens,labelsep=quad, skip=3pt]{caption}
\usepackage{graphicx}
\usepackage{enumerate,braket,tcolorbox}
\usepackage[localise]{xepersian}
%\settextfont[Scale=1.2]{‌BNAZANIN.TTF}
%\settextfont[Scale=1.2]{BZAR.TTF}
\settextfont[Scale=1]{XB Niloofar}
\ExplSyntaxOn
\cs_set_eq:NN
\etex_iffontchar:D
\tex_iffontchar:D
\cs_undefine:N \c_one
\int_const:Nn \c_one { 1 }
\ExplSyntaxOff
\setdigitfont[Scale=1]{XB Niloofar}
\setlatintextfont[Scale=1]{Times New Roman}

% set local changes to margin
\def\changemargin#1#2{\list{}{\rightmargin#2\leftmargin#1}\item[]}
\let\endchangemargin=\endlist 
%

% newcommands
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}

\begin{document}
\title{مطالعه همگامی در شبکه‌های عصبی مهاری} 
\author{محسن مهرانی - استاد راهنما: دکتر سامان مقیمی عراقی}
\date{}
\maketitle
\tableofcontents
\newpage
\قسمت{سخن نخست}
مطالعه فعالیت شبکه‌های عصبی برای تحقیق و بررسی کارکردهای مغز اهمیت زیادی دارد. همه بر این باوریم که مغز محمل اندیشه و تفکر است. ما کنجکاو هستیم که چگونه همکاری بین نورون‌های آن باعث می‌شود تا حافظه، کشف و پردازش صورت گیرد. هر کدام از نورون‌های مغز می‌تواند در حالت فعال [روشن] یا غیرفعال [خاموش] قرار گیرد. هم اکنون شواهدی وجود دارد که کارکردهایی طلایی یاد شده مغز در زمان‌هایی رخ می‌دهند که الگوی خاموش و روشن شدن نورون‌های آن باهم \textbf{«هم‌گامی»} دارند. هم‌گامی به این معناست که جمعیت بزرگی از نورون‌ها هم باهم خاموش و روشن می‌شوند و یک الگوی تکرار شونده‌ای را دنبال می‌کنند. تو گویی که باهم هم‌آهنگ یا هم‌گام شده‌اند.\\

بی‌تردید دستیابی به تمام جزییات مغز برای ما میسّر نیست و به آن به عنوان یک \textbf{«جعبه‌ی سیاه»} نگاه می‌کنیم که مدت‌هاست به دنبال ارائه مدلی هستیم که رابطه‌ی بین ورودی‌ها و خروجی‌های ثبت شده را بازتولید کند. کاری که در این پژوهش انجام خواهیم داد تلاشی است برای پیشنهاد دادن یک مدل برای این جعبه‌ی سیاه که رفتار نسبتا مشابهی را میان ورودی و خروجی‌های این جعبه سیاه و یا مغز ایجاد می‌کند.

\قسمت{مقدمه}
مدل‌های زیادی برای شبکه‌های عصبی ارائه شده است که توانایی تولید رفتار هم‌گام شدن نورون‌ها را در آن‌ها می‌توانیم جستجو کنیم. یکی از این مدل‌ها که در تمام فصول شبیه‌سازی از آغاز تا کنون از آن بهره برده شده است؛ مدل انباشت و شلیک است\cite{PhysRevLett.105.158104}. در این جستار ابتدا با مدل انباشت و شلیک شروع می‌کنیم و سپس مدلی توسعه یافته که آن را \textbf{«چرخنده»} صدا خواهیم کرد؛ می‌پردازیم.\\
متن اصلی این جستار شامل معرفی این مدل‌ها و پویایی آن‌ها در زمان و نتایج ضبط شده از نشانگرهایی است که برای آشکارسازی هم‌گامی تعبیه شده‌اند.

%\input{chapters/integrate_and_fire_synchronization.tex}

\section*{فرصتی برای مدل‌های دیگر نورونی}
در بخش قبل به بررسی ویژگی‌های مدل انباشت‌-شلیک پراختیم. اگر چه این مدل بسیار ساده توانست رفتارهای آشنایی را برای ما بازتولید کند اما شامل محدودیت‌هایی است. این محدودیت‌ها باعث می‌شود تا ما به سراغ مدل‌های نورونی دیگری مانند نورون‌های چرخنده برویم.\\
این مدل نسبت به مدل قبلی شامل ویژگی‌های مثبتی است. یکی از ویژگی‌های خوب آن این است که پس از بازنشانی فاز نورون تیزه زده، فاز آن به زاویه‌ای برده می‌شود که دارای خواص مثلثاتی مشابهی است. به این معنا که دیگر شاهد گسستگی در اندازه‌ی جملاتی که تحول نورون را توصیف می‌کنند؛ نیستیم.\\
%\input{chapters/rotational_synchronization.tex}
%\input{chapters/simple_synchronization.tex}


\قسمت{تلاش برای توصیف}

از آنجا که شبیه‌سازی این سامانه شامل تعریف فرآیندهای متفاوتی بود؛ بدیهی است که نوشتن معادله‌ی تحلیلی برای توصیف کامل آن آسان نباشد. اما در این بخش تلاش می‌کنیم که با کنار هم قرار دادن معادلات اصلی چارچوب مسئله‌ی خود را مشخص کنیم.\\
هر نورون که از حالت $\theta = \pi$ عبور می‌کند [تیزه می‌زند] باعث می‌شود تا سهمی از جریان با کیفیت $p(t):= \alpha^2 t \cdot exp(-\alpha t)$ به جریان درونی کل سامانه $E(t)$ اضافه شود.
\begin{equation}
E(t) = \frac{1}{N}\int_{0}^{\infty} \int J_a (\pi,t-d-u) da \cdot u\, e^{-\alpha u} du
\end{equation}
(چک شود آیا بعد معادله درست است؟)\\
اما جریان برای هر نورون با ورودی $a$ به طریق زیر است:
\begin{equation}
J_a (\theta, t) = n_a(\theta,t) \cdot \dot \theta_a
\end{equation}
این رفتار به خوبی نشان می‌دهد جریان فقط در ناحیه‌ی $\theta \leq \pi$ وجود دارد. زیرا ورود نورون به ناحیه‌ی مثبت‌تر را ممنوع کرده‌ایم.  بی‌تردید برای فهمیدن چگونگی تغییر جریان در ناحیه‌های میانی باید از معادله‌ی پخش استفاده کنیم.
\begin{align}
\frac{\partial n_a}{\partial t} &= - \frac{\partial J_a}{\partial \theta}\\
&= - \frac{\partial n_a}{\partial \theta} \cdot \dot \theta_a
\end{align}
\زیرقسمت{حل معادله‌ی شبکه‌ی ساده}
اجازه بدهید تا اولین تلاش خود را از ساده‌ترین نوع شبکه‌ها شروع کنیم. شبکه‌ای که به جز جریان داخلی و جریان تصادفی اولیه ورودی دیگری ندارد. پس خواهیم داشت:
\begin{align}
\begin{cases}
E(t) = \frac{1}{N} \int_{0}^{\infty} \int n_a(\pi,t-d-u) \cdot \big[ a - g E(t-d-u) \big] da \cdot \alpha^2 u\, e^{-\alpha u} du \\
\frac{\partial n_a}{\partial t} = - \frac{\partial n_a}{\partial \theta} \cdot (a - g E(t) )
\end{cases}
\label{eq:simple_network}
\end{align}
چند پیشنهاد می‌شود برای ادامه‌ی راه‌حل داشت.
\begin{enumerate}[1.]
\item
از آنجا که میدان به گونه‌ای متناوب عمل می‌کند؛ یک پیشنهاد خوب می‌تواند آن باشد که بسط فوریه‌ی آن را بنویسیم.
\begin{equation}
E(t) = \sum c_i \cdot cos(\omega_i t)
\end{equation}
که اگر ثابت کنیم $c_1$ از بقیه ضرایب بزرگتر است؛ مساله‌ی ما حل می‌شود.
\item
دشواری مساله از در هم تنیدگی معادلات برآمده است. اگر به تقریب در معادله‌ی پخش میدان را یک نوفه درنظر بگیریم و پاسخ را در معادله‌ی اول قرار دهیم.
\item
انتگرال اول را به صورت بازگشتی در خودش جاگذاری کنیم.
\item
مسئله را در حالت آماری بررسی کنیم و حالت پایستار آن را پیدا کنیم و  بپرسیم در چه حالتی است که حالت پایستار داریم.
\end{enumerate}

\زیرزیرقسمت{روش بازگشتی}
در این روش برای این که از جمله‌ی تابعیت $E(u)$ را از خودش باز کنیم؛ عبارت سمت راست را مجددا در خودش جاگذاری می‌کنیم. برای راحت‌تر شدن محاسبات ابتدا دو متغیر کمکی زیر را تعریف می‌کنیم:
% abbrivations for calculation of this section
\newcommand{\J}[1]{\mathcal{J}(\pi,t - d - u_{#1})}
\newcommand{\N}[1]{\mathcal{N}(\pi,u_{#1})}

\newcommand{\A}[1]{\mathcal{A}(#1 - d)}

\newcommand{\impact}[1]{u_{#1}\, e^{-\alpha u_{#1}}}
%
\begin{align}
\J{} &\equiv \int n_a(\pi,t-d-u) a \cdot da\\
\N{} &\equiv \int n_a(\pi,t-d-u) \cdot da
\end{align}
عبارت $\J{}$ به معنای جمع جریان تصادفی نورون‌هایی است که در زمان u در آستانه قرار دارند. همچنین عبارت $\N{}$ به معنای تعداد همین نورون‌هاست.\\
حال با نمادهای بالا شروع به بازنویسی جملات پیشین می‌کنیم:
\begin{align}
E(t) &= \frac{1}{N} \int_{0}^{\infty} \J{} \cdot u\, e^{-\alpha u} du  - \frac{g}{N}\int_{0}^{\infty} \N{} \cdot u\, e^{-\alpha u} E(t-d-u)  du\\
\end{align}
حال جمله‌ی اول را نیز با عبارت دیگری خلاصه‌سازی می‌کنیم:

\begin{equation}
\A{t} \equiv \frac{1}{N}\int_{0}^{\infty} \J{} \cdot u\, e^{-\alpha u} du 
\end{equation}
این عبارت جمع تعداد همه‌ی تیزه‌هایی است که تا گام $t-d$ زده شده‌اند و درنتیجه جمله‌ای انباشتی است. پس خواهیم داشت:
\begin{changemargin}{-3cm}{-3cm} 
%your text here  
\begin{align}
E(t) &= \A{t} - g\int_{0}^{\infty} \N{} \cdot u\, e^{-\alpha u}E(t-d-u) du\\
&= \A{t} - g\int_{0}^{\infty} \N{1} \cdot \impact{1} \cdot \big[ \A{u_1} - g\int_{- \infty}^{u_1 - d} \N{2} \cdot \impact{2} E(u_2) du_2 \big] du_1\\
&= \A{t} - g\int_{- \infty}^{t - d} \N{1} \cdot \impact{1} \cdot \A{u_1} du_1\\ 
&\hspace{1 cm}+ g^2 \int_{- \infty}^{t - d} \N{1} \cdot \impact{1}\int_{- \infty}^{u_1 - d} \N{2} \cdot \impact{2} E(u_2) du_2 du_1\\
&= \A{t} - g\int_{- \infty}^{t - d} \N{1} \cdot \impact{1} \cdot \A{u_1} du_1\\ 
&\hspace{1 cm}+ g^2 \int_{- \infty}^{t - d} \N{1} \cdot \impact{1}\int_{- \infty}^{u_1 - d} \N{2} \cdot \impact{2} \A{u_2} du_2 du_1\\
&\hspace{1 cm}- g^3 \int_{- \infty}^{t - d} \N{1} \cdot \impact{1}\int_{- \infty}^{u_1 - d} \N{2} \cdot \impact{2} \int_{- \infty}^{u_2 - d} \N{3} \cdot \impact{3} E(u_3) du_3 du_2 du_1
\end{align}

\end{changemargin}

حال در این میان دو نکته قابل توجه است. (۱) میدان در هر زمان وابسته به اثرات انباشتگی از زمان ازل سامانه است. عمر این سامانه کراندار باشد؛ تعداد جملات بالا محدود می‌شوند. (۲) دقت کنید که بازه‌ی متغیرهای انتگرال‌ده به صورت 
$- \infty \leq u_{i+1} \leq u_i - d$
محدود می‌شوند. پس طبیعی است که نتیجه بگیریم بازه‌ی هر انتگرال تو در تو چند گام عقب‌تر از زمان اکنون است. یعنی 
$- \infty \leq u_{i} \leq t - i \, d$.


\زیرزیرقسمت{روش اختلال}
به نمودار \ref{fig:sigma_rotational} دقت کنید. در زمانی که تعداد نورون‌ها بی‌نهایت باشد؛ در فاز ناهم‌گام انحراف معیار میدان صفر خواهد شد. این به این معنی است که جریان در زمان ثابت خواهد ماند. پس بگذارید با علم بر این موضوع یک جواب معادله‌ی \ref{eq:simple_network} را در حالت حدی میدان ثابت $E_0$ معرفی کنیم.\\
با فرض ثابت بودن میدان، اندازه‌ی آن را محاسبه می‌کنیم. سپس مجدد به معادلات برمی‌گردیم و می‌پرسیم که در صورت جمع با یک جمله‌ی اختلالی کوچک این انحراف رشد خواهد کرد یا خیر. به عبارت دیگر آیا این جواب جاذب است.\\
\begin{align}
\begin{cases}
E_0 = \frac{1}{N}\int_{- \infty}^{t - d} \int n_a(\pi,u) \cdot \big[ a - g E_0 \big] da \cdot \alpha^2 u\, e^{-\alpha u} du \\
\frac{\partial n_a}{\partial t} = - \frac{\partial n_a}{\partial \theta} \cdot (a - g E_0 )
\end{cases}
\end{align}

یک راه خوب برای پیشبرد سطر اول معادلات آن است که از دو طرف آهنگ تغییرشان با زمان را بپرسیم. از آنجا که سمت چپ معادله ثابت است؛ سمت راست هم باید جوابی مشابه را حکایت کند.\\
\begin{equation}
0 = \frac{dE_0}{dt} = \frac{\alpha^2 (t-d) e^{-\alpha (t-d)}}{N} \cdot [ - gE_0 \cdot \int n_a(\pi,t-d) da + \int n_a(\pi,t-d)\cdot a\,da ]
\end{equation}
مشخص است که کدام جمله از جملات ضربی بالا صفر است. پس برای $E_0$ خواهیم داشت:
\begin{equation}
E_0 = \frac{1}{g}\cdot \frac{\int n_a(\pi,t-d)\cdot a\,da}{\int n_a(\pi,t-d) da }
\end{equation}

حال برای ادامه‌ی فرآیند نیاز داریم تا عبارت حاکم بر 
$n_a(\pi,t-d)$
را بدست آوریم. جواب پیشنهادی ما برای سطر دوم معادلات از جنس تابع دلتاست:
\begin{align}
n_a(\theta,t) &= \delta(\theta - \theta_a(t)) \\
&= \delta(\theta + \theta_0 - (a - g E_0)t + 2 \floor{K^{(t)}_a}\pi )\\
&= \delta( \theta - (a - g E_0)t + 2 \floor{K^{(t)}_a} \pi + \theta_0  )\\
\Rightarrow n_a(\pi,t) &= \delta(  (2\floor{K^{(t)}_a} + 1)\pi - (a - g E_0)t + \theta_0   )\\
\end{align}
که در این معادلات 
$K^{(t)}_a$
کسری است که تعداد دور هر نورون را از آغاز تا کنون روایت می‌کند و ما مجبور به عقب کشیدن 
$2\pi$
فاز کامل پس از تیزه زدن آن به تعداد 
$\floor{K^{(t)}_a}$
شده‌ایم.
\footnote{دقت کنیم که معادله‌ی ذکر شده برای نورون‌هایی درست است که 
$(a - g E_0) > 0 $
}
  قابل محاسبه است که عبارت کامل آن به صورت زیر است.
\begin{equation}
K^{(t)}_a = \frac{(a - gE_0)t + \pi + \theta_0}{2\pi}
\end{equation}

برای محاسبه‌ی انتگرال‌هایی که شامل این دلتای دیراک هستند؛ لازم است تا صفر‌های آرگومان آن را محاسبه کنیم.
\begin{align}
\big( 2 \floor{\frac{(a - gE_0)t + \pi + \theta_0}{2\pi}} + 1 \big)\pi - (a - g E_0)t + \theta_0 &= 0\\
2\pi \times \bigg( \floor{\frac{(a - gE_0)t + \pi + \theta_0}{2\pi}}  - \frac{(a - gE_0)t + \pi + \theta_0}{2\pi} \bigg) &= 0\\
2\pi \times \bigg( \floor{K^{(t)}_a} - K^{(t)}_a \bigg) &= 0  \label{eq:neuron_pattern_simple_model}
\end{align}
این رابطه کاملا یک تابع تناوبی را توصیف می‌کند. یک تابع مقطع که در مکانی که آرگومان آن صحیح می‌شود؛ مقدار صفر به خود می‌گیرد. پس روشن است که توقع داشته باشیم. تعداد صفرهای این معادله به اندازه‌ی تعداد تناوبی است که در هر زمان در بازه‌ی جریان‌های داده شده دارد.
\begin{align}
\Delta K^{(t)}_a  &= 1\\
\Delta K^{(t)}_a &= \frac{t}{2\pi}\Delta a\\
\Delta a &= \frac{2\pi}{t}
\end{align}
این دوره‌ی تناوب با افزایش زمان کوچکتر می‌شود. اگر تعداد نورون‌ها را به صورتی ترمودینامیکی بزرگ بگیریم؛ آنگاه به ازای هر دوره‌ی تناوب یک نورون حتما هست که روی محور آستانه قرار گرفته است.\\
حال که دوره‌ی تناوب 
$\Delta a$
را بدست آوردیم؛ می‌دانیم که ریشه‌های رابطه‌ی 
\ref{eq:neuron_pattern_simple_model}
چه زمانی رخ می‌دهند. فرض کنیم که اولین صفر در جریانی مثل
$a_m$
رخ می‌دهد. توجه کنید حتما اندازه‌ی این جریان به گونه‌ای است که نورون را به صورت فعال نگه دارد. پس باید حتما
$(a_m - g E_0) > 0 $
باشد.
 حال می‌توانیم انتگرال‌های مورد نظر خود را این چنین بسط دهیم.

\begin{align}
\int n_a(\pi,t-d)a\,da &= \int \delta \bigg( 2\pi ( \floor{K^{(t)}_a} - K^{(t)}_a) \bigg) a\,da\\
&= \frac{1}{2\pi} \cdot \sum_{K^{(t)}_a \in Z} a_i \\
&= \frac{1}{2\pi} \cdot \sum^{M}_{m=0} a_m + m \cdot \Delta a\\
&= \frac{M+1}{2\pi} \cdot ( \frac{a_m +a_{max} }{2} )\\
\end{align}
و از طرفی:
\begin{align}
\int n_a(\pi,t-d)\,da &= \int \delta \bigg( 2\pi ( \floor{K^{(t)}_a} - K^{(t)}_a) \bigg) a\,da\\
&= \frac{1}{2\pi} \cdot \sum_{K^{(t)}_a \in Z} 1 \\
&= \frac{1}{2\pi} \cdot \sum^{M}_{m=0}  1\\
&= \frac{M+1}{2\pi}
\end{align}
حال اگر به محاسبه‌ی میدان ثابت خود برگردیم و تکه‌های پازل را کنار هم بگذاریم؛ خواهیم داشت:
\begin{align}
E_0 &= \frac{1}{g}\cdot \frac{\int n_a(\pi,t-d)\cdot a\,da}{\int n_a(\pi,t-d) da } \\
&= \frac{1}{g}\cdot \frac{ \frac{M+1}{2\pi} \cdot ( \frac{a_m +a_{max} }{2} ) }{ \frac{M+1}{2\pi} } \\
&= \frac{1}{g} ( \frac{a_m +a_{max} }{2} )
\end{align}

\زیرزیرقسمت{روش آماری}
در این روش فرض می‌کنیم که برای هر جریان تصادفی اولیه، نورون‌های زیادی را به اختیار گرفته‌ایم. در حالت پایا  ، در یک حالت خاص تغییری در چگالی جمعیت مشاهده نمی‌شود پس در معادله‌ی
\ref{eq:simple_network}
خواهیم داشت:
\begin{equation}
\frac{\partial n_a}{\partial t} = 0
\end{equation}
همچنین در حالت پایا که در واقع از نگاه ما حالت ناهم‌گام است؛ جریان بین نورون‌ها - که کمیتی بزرگ مقیاس است -  در زمان تغییری نمی‌کند. پس به این ترتیب:

\begin{align}
\begin{cases}
\frac{\partial n_a}{\partial t} = - \frac{\partial J_{a}(t)}{\partial \theta} = 0\\
J_{a}(\theta, t) = n_a(\theta,t) \cdot [ a - g E ]\\
\end{cases}
\Rightarrow J_{a}(\theta, t) = J_{a}(t)\\
\Rightarrow n_{a}(\theta, t) = n_{a}\\
\end{align}

پس توزیع جمعیت نورون‌‌ها مستقل از زمان و حالت آن‌ها خواهد شد. اگر توزیع را در ابتدا یکنواخت میان جریان‌های مختلف توزیع کرده باشیم؛ برای همه‌ی زمان‌ها و حالت‌ها داریم:
\begin{equation}
n = \frac{N}{2 \pi (a_{Max} - a_{min}) }
\end{equation}


برای جریان بین نورون‌ها هم خواهیم داشت:
\begin{align}
E &= \frac{1}{N} \int_{- \infty}^{t - d} \int n \cdot \big[ a - g E \big] da \cdot \alpha^2 u\, e^{-\alpha u} du\\
&=  \int \frac{n}{N} \cdot \big[ a - g E \big] da \label{eq:e_sum_simple}
\end{align}
دقت کنیم که انتگرال رابطه‌ی \ref{eq:e_sum_simple} روی  نورون‌هایی است که مستعد تیزه زدن هستند.
\footnote{
$(a - g E) > 0 $
}

اولین جریانی که نورون را مستعد تیزه زدن می‌کند $a_*$ نام‌گذاری می‌کنیم. وقتی جریان مهاری حاصل از تیزه زدن‌ها کوچک است؛ همه‌ی نورون‌ها فعال هستند و در نتیجه‌ 
$a_* = a_{min}$
می‌شود. اما در حالتی که جریان مهاری زیاد می‌شود؛ این مقدار از کمترین جریان تصادفی اولیه سامانه بزرگتر می‌شود. محاسبات را ادامه می‌دهیم:
\begin{align}
E &=  \int \frac{n}{N} \cdot \big[ a - g E \big] da \\
&= \frac{n}{N} \cdot \big[ \frac{a^2_{Max} - {a_*}^2}{2} - g E (a_{Max} - a_*) \big] \\
\Rightarrow E &= n \cdot \big[ \frac{a^2_{Max} - {a_*}^2}{2}  \big] / \big[ N + g n (a_{Max} - a_*)\big]
\label{}
\end{align}
شاید بنظر این یک معادله‌ی درجه یک ساده باشد که میدان را گزارش می‌کند اما در واقع خود $a^*$ هم به میدان وابسته است و باید وابستگی آن را لحاظ کنیم. به تقریب:
$a^{*} = gE$
با اضافه کردن این معادله و حل معمول یک معادله‌ی درجه‌ی دو برای میدان صراحتا خواهیم داشت:
\begin{align}
E =  \big( \frac{a_{Max}}{g} + \frac{N}{n g^2}  \big) \pm \big[ \big( \frac{N}{n g^2} + \frac{a_{Max}}{g} \big)^2 - \frac{{a_{Max}}^2}{g^2} \big]^{\frac{1}{2}}
\end{align}
نتیجه می‌دهد که $a_{*}$ هم باید به صورت زیر باشد:
\begin{align}
a_{*} &=  \big( a_{Max} + \frac{N}{n g} \big) \pm \big[ \big( \frac{N}{n g} + a_{Max} \big)^2 - {a_{Max}}^2 \big]^{\frac{1}{2}}\\
&=  \big( a_{Max} + \frac{N}{n g} \big) \pm \big[  \frac{N^2}{n^2 g^2} + \frac{2a_{Max}}{ng}  \big]^{\frac{1}{2}}
\end{align}
اجازه بدهید علامت مثبت را کنار بگذاریم زیرا مقدار $a_{*}$ را خارج بازه‌ی جریان‌های سامانه گزارش می‌کند. پس هم برای میدان و هم جریان $a_{*}$ خواهیم داشت:
\begin{align}
\begin{cases}
a_{*} =  \big( a_{Max} + \frac{N}{n g} \big) - \big[  \frac{N^2}{n^2 g^2} + \frac{2a_{Max}}{ng}  \big]^{\frac{1}{2}}\\
E =  \big( \frac{a_{Max}}{g} + \frac{N}{n g^2} \big) - \big[ \frac{N^2}{n^2 g^4} + \frac{2Na_{Max}}{ng^3}  \big]^{\frac{1}{2}}\\
\end{cases}
\end{align}

حال اگر نتایج بدست آمده را با داده‌های شبیه‌سازی تطبیق دهیم؛ خواهیم دید که تطابق خوبی با یک دیگر دارند.

\begin{figure}
	\centering
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../scripts/all_neurons_model_in_one_place/Non_repulsive_rotational_ensembles/N10000_T100_I9.5_13.5_v1.0/field_zeroth_order_asterix_g_0.1_130.png}
		\caption{نسخه‌ای که کمینه‌ی جریان را از حل محاسبات درنظر می‌گیرد}
		\label{fig:e_zeroth_not_all_gifted}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../scripts/all_neurons_model_in_one_place/Non_repulsive_rotational_ensembles/N10000_T100_I9.5_13.5_v1.0/field_zeroth_order_simple_g_0.1_130.png}
		\caption{نسخه‌ای که همه‌ی نورون‌ها را فعال تصور می‌کند.}
		\label{fig:e_zeroth_all_gifted}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.3\textwidth}
		\centering
		\includegraphics[width=\textwidth]{../scripts/all_neurons_model_in_one_place/Non_repulsive_rotational_ensembles/N10000_T100_I9.5_13.5_v1.0/field_zeroth_order_developed_g_0.1_130.png}
		\caption{نسخه ساخته شده از اتصال دوتای دیگر}
		\label{fig:e_zeroth_developed}
	\end{subfigure}
	\caption{تطابق جریان پایای بدست آمده از حل عددی و تحلیلی}
	\label{fig:three graphs}
\end{figure}

در ضریب تاثیرهای بسیار بزرگ داریم:(اشتباه است تصحیح شود.)
\begin{align}
E \cong & \frac{a_{Max}}{g} + \frac{N}{ng^2} - (\frac{2N a_{Max}}{n g^3})^{\frac{1}{2}} \big[ 1 + \frac{N}{2nga_{Max}} \big]^{\frac{1}{2}}\\
=& \frac{a_{Max}}{g} + \frac{N}{ng^2} - (\frac{2 N a_{Max}}{n g^3})^{\frac{1}{2}} \big[ 1 + \frac{N}{4nga_{Max}} \big]\\
=& \frac{a_{Max}}{g} - (\frac{2 N a_{Max}}{n g^3})^{\frac{1}{2}} + \frac{N}{ng^2}  - (\frac{N}{2n})^{\frac{3}{2}}  \cdot \frac{1}{ {a^{\frac{1}{2}}_{Max} g^{\frac{5}{2}}}}
\end{align}

\subsubsection{میانگین زمانی میدان}
اگر چه محاسبه‌ی انحراف معیار میدان در طول زمان کار دشواری است اما محاسبه‌ی میانگین آن نسبتا ساده‌تر است. زیرا برای هر تابع f وابسته به زمان داریم
\begin{align}
I[f] &= \lim_{T\to\infty} \frac{1}{T - d} \int^{T}_{d} dt \int_{0}^{t - d} f(u)du \\
&= \lim_{T\to\infty} \frac{1}{T - d} \int_{0}^{T - d} du \int^{T}_{u+d} f(t) dt \\
&= \lim_{T\to\infty} \int_{0}^{T - d} du \bar{f}(u)  
\end{align}
به شرط تعادل

\زیرزیرقسمت{حل اختلالی میدان}
همان طور که مشخص است؛ حل دقیق میدان بسیار کار دشواری است اما می‌توان از طریق ترفندهای اختلالی به جواب آن نزدیک شد. یکی از روش‌های معمول حل زنجیری و تودرتوی دستگاه معادلات است. \\
به این ترتیب که ابتدا از معادله  پاسخ حالت پایا (مرتبه‌ی صفرم) را در معادله‌ی پخش جاگذاری می‌کنیم تا توزیع آماری وابسته به زمان نورون‌ها بدست آید. سپس مجددا از توزیع بدست آمده؛ میدان مرتبه‌ی اول را که وابسته به زمان است؛ محاسبه می‌کنیم.\\
از آنجا که توزیع سامانه‌ رفتاری دوره‌ای به طول $2\pi$ دارد؛ می‌توانیم آن را به صورت زیر بسط دهیم:
\begin{align}
	\rho(\theta, a, t) = \rho_0 + \sum_k A_k(t) e^{ik\theta}, \quad k \in \mathcal{Z}
\end{align}

\begin{align}
	\frac{\partial \rho}{\partial t} &= \sum \dot A_k e^{ik\theta}\\
	\frac{\partial \rho}{\partial \theta} &= \sum A_k \cdot ik \cdot e^{ik\theta}\\
\end{align}
حال آن را در معادله‌ی پخش قرار می‌دهیم تا بتوانیم معادله‌ی حاکم بر ضرایب را محاسبه کنیم.
\begin{align}
	\sum \dot A_k e^{ik\theta} &= - \sum A_k \cdot ik(a - gE(t)) \cdot e^{ik\theta}\\
	\Rightarrow \dot A_k &= - A_k \cdot ik(a - gE(t))
\end{align}
در تقریب مرتبه‌ی اول برای توزیع داریم:
\begin{align}
	\dot A_k &= - A_k \cdot ik(a - g E_0)\\
	\Rightarrow A_k(t) &= A_k(0) e^{- ik(a-gE_0)t}\\
	\Rightarrow \rho(\theta, a, t) &= \rho_0 + \sum_k A_k(0) e^{ik\theta - ik(a - gE_0)t}
\end{align}
پس برای نورون‌های روی آستانه خواهیم داشت:
\begin{align}
	\rho(\pi, a, t) = \rho_0 + \sum_k A_k(0) e^{ik\pi - ik(a - gE_0)t}
\end{align}
حال از نتیجه‌ی بدست آمده استفاده می‌کنیم و همان طور که اشاره شد به محاسبه‌ی مرتبه‌ی بعدی میدان می‌رویم:
\begin{align}
	E(t) &= \int \int_{0}^{\infty} \rho(\pi, a, t-d-v)\cdot \dot \theta \cdot \alpha^2 ve^{-\alpha v} dv da \\
	&= E_0\\
	&+ \int \int_{0}^{\infty} \sum_k A_k(0) e^{ik\pi - ik(a - gE_0)(t-d - v)} \cdot (a - gE_0) \alpha^2 ve^{-\alpha v} dv da \\
	&= E_0 + \sum_k \int \int_{0}^{\infty} A_k(0) e^{ik\pi - ik(a - gE_0)(t-d - v)} \cdot (a - gE_0) \alpha^2 ve^{-\alpha v} dv da
\end{align}
اجازه بدهید سهم مدهای متفاوت از میدان را به صورت جداگانه محاسبه کنیم و سپس مجددا در کنار یکدیگر قرار دهیم.
\begin{align}
	E_{k,a}(t) = -\alpha^2 A_k(0)(a - gE_0) e^{ik\pi}\int^{\infty}_{0} v e^{-[\alpha - ik(a - gE_0)]v-ik(a - gE_0)(t-d)} dv
\end{align}
با با تغییر متغیر 
$\beta \equiv \alpha - ik(a-gE_0)$
محاسبات را ادامه می‌دهیم:
\begin{align}
	&= \alpha^2 A_k(0) (a - gE_0) e^{ik\pi} e^{-ik(a-gE_0)(t-d)} \cdot \int^{\infty}_0 v e^{-\beta v}dv \\
	&= \alpha^2 A_k(0) (a - gE_0) e^{ik\pi} e^{-ik(a-gE_0)(t-d)} \cdot \frac{1}{\beta^2} \\
	&= A_k(0) (a - gE_0) e^{ik[\pi -(a-gE_0)(t-d)]} \cdot (\frac{\alpha}{\alpha-ik(a-gE_0)})^2
\end{align}
حال قدم به قدم به محاسبات پیشین خود برمی‌گردیم. ابتدا می‌پرسیم میدان همه‌ی نورون‌های با مد یکسان چه جریانی را تولید می‌کنند.
\begin{align}
	E_k(t) &= \int E_{k,a} da\\
	&= \int A_k(0) (a - gE_0) e^{ik[\pi -(a-gE_0)(t-d)]} (\frac{\alpha}{\alpha-ik(a-gE_0)})^2 da
\end{align}
با تغییر متغیر
$h \equiv a - gE_0$
تلاش می‌کنیم انتگرال را ادامه دهیم.
\begin{align}
	E_k(t) = A_k(0)e^{ik\pi} \int^{a_M - gE_0}_{0} h e^{-ikh(t-d)} (\frac{1}{1 - ikh/\alpha})^2 dh
\end{align}
نرم‌افزارهای محاسباتی همچون ابزار ولفرم به ما امکان می‌دهد تا پاسخ آن را به صورت زیر بیان کنیم:
\begin{align}
	E_k(t) = -A_k(0)\frac{\alpha^2}{k^2} e^{ik\pi} &\bigg[ \frac{ e^{-i(\xi_{(h)} + k(t-d)h)} }{\sqrt{1 + h^2 k^2/\alpha^2}} \\
	&+ e^{-\alpha(t-d)}(\alpha(t-d) + 1) Ei[(\alpha-ikh)(t-d)] \, \bigg]	\Biggr|_{0}^{a_M -gE_0}
\end{align}
به صورتی که 
$e^{-i\xi_{(h)}} = \frac{1 + ikh/\alpha}{\sqrt{1 + h^2 k^2/\alpha^2}}$
است و 
$Ei$
همان تابع انتگرال نمایی است که به صورت 
$Ei[z] = - \int^{+\infty}_{-z} e^{-t}/t dt$
نوشته می‌شود.
\begin{align}
	E_k(t) =& - A_k(0) \frac{\alpha^2}{k^2} e^{ik\pi} \bigg[ \frac{ e^{-i(\xi_{(a_M -gE_0)} + k(t-d)(a_M -gE_0))} }{\sqrt{1 + (a_M -gE_0)^2 k^2/\alpha^2}} \\
	&+ e^{-\alpha(t-d)}(\alpha(t-d) + 1) Ei[(\alpha-ik(a_M -gE_0))(t-d)] \\
	&- e^{-ik(t-d)(a_M -gE_0)} \\
	&- e^{-\alpha(t-d)}(\alpha(t-d) + 1) Ei[\alpha(t-d)] \bigg]\\
	=&- A_k(0) \frac{\alpha^2}{k^2} e^{ik\pi} \bigg[ e^{-ik(t-d)(a_M -gE_0)} \bigg( \frac{ e^{-i(\xi_{(a_M -gE_0)})} }{ \sqrt{1 + (a_M -gE_0)^2 k^2/\alpha^2} } + 1\bigg) \\
	&+ e^{-\alpha(t-d)}(\alpha(t-d) + 1)\bigg( Ei[(\alpha-ik(a_M -gE_0))(t-d)] - Ei[\alpha(t-d)] \bigg) \bigg]
\end{align}
پس یک جمله‌ی نوسانی دارد و جمله‌ای که شامل تکینگی است.
\newpage
\bibliographystyle{plain-fa}
\bibliography{MyReferences}

\end{document}


